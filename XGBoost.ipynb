{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "#import sklearn\n",
    "#import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\",encoding = \"ISO-8859-1\")\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abia</th>\n",
       "      <th>...</th>\n",
       "      <th>money_related</th>\n",
       "      <th>tiene_fecha</th>\n",
       "      <th>has_year</th>\n",
       "      <th>tiene_hora_2</th>\n",
       "      <th>tiene_hora</th>\n",
       "      <th>repeticiones</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abia  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "2   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "3   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "4   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   money_related  tiene_fecha  has_year  tiene_hora_2  tiene_hora  \\\n",
       "0          False        False     False         False       False   \n",
       "1          False        False     False         False       False   \n",
       "2          False        False     False         False       False   \n",
       "3          False        False     False         False       False   \n",
       "4          False        False     False         False       False   \n",
       "\n",
       "   repeticiones  longitud_tweet  letras_seguidas  sentimiento  objetividad  \n",
       "0             1              40                2        -1.00         1.00  \n",
       "1             1              70                2         0.25         0.55  \n",
       "2             1             100                2         0.00         0.00  \n",
       "3             1              40                1         0.00         0.00  \n",
       "4             1              50                2         0.00         0.00  \n",
       "\n",
       "[5 rows x 5014 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_limpio = pd.read_csv(\"test_limpio_con_BOW_de_5000_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "test_limpio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abia</th>\n",
       "      <th>...</th>\n",
       "      <th>money_related</th>\n",
       "      <th>tiene_fecha</th>\n",
       "      <th>has_year</th>\n",
       "      <th>tiene_hora_2</th>\n",
       "      <th>tiene_hora</th>\n",
       "      <th>repeticiones</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 5015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abia  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   money_related  tiene_fecha  has_year  tiene_hora_2  tiene_hora  \\\n",
       "0          False        False     False         False       False   \n",
       "1          False        False     False         False       False   \n",
       "\n",
       "   repeticiones  longitud_tweet  letras_seguidas  sentimiento  objetividad  \n",
       "0             1              70                2          0.0          0.0  \n",
       "1             1              40                1          0.1          0.4  \n",
       "\n",
       "[2 rows x 5015 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_limpio = pd.read_csv(\"train_limpio_con_BOW_de_5000_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "train_limpio.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       1\n",
       "10      1\n",
       "11      1\n",
       "12      1\n",
       "13      1\n",
       "14      1\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "6967    0\n",
       "6968    0\n",
       "6969    0\n",
       "6970    0\n",
       "6971    0\n",
       "6972    0\n",
       "6973    0\n",
       "6974    0\n",
       "6975    0\n",
       "6976    1\n",
       "6977    1\n",
       "6978    0\n",
       "6979    1\n",
       "6980    1\n",
       "6981    1\n",
       "6982    1\n",
       "6983    1\n",
       "6984    0\n",
       "6985    1\n",
       "6986    1\n",
       "6987    1\n",
       "6988    1\n",
       "6989    1\n",
       "6990    1\n",
       "6991    1\n",
       "6992    1\n",
       "6993    1\n",
       "6994    1\n",
       "6995    1\n",
       "6996    1\n",
       "Name: target, Length: 6997, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y=train_limpio.target\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abia</th>\n",
       "      <th>...</th>\n",
       "      <th>money_related</th>\n",
       "      <th>tiene_fecha</th>\n",
       "      <th>has_year</th>\n",
       "      <th>tiene_hora_2</th>\n",
       "      <th>tiene_hora</th>\n",
       "      <th>repeticiones</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.01875</td>\n",
       "      <td>0.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abia  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "2   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "3   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "4   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   money_related  tiene_fecha  has_year  tiene_hora_2  tiene_hora  \\\n",
       "0          False        False     False         False       False   \n",
       "1          False        False     False         False       False   \n",
       "2          False        False     False         False       False   \n",
       "3          False        False     False         False       False   \n",
       "4          False        False     False         False       False   \n",
       "\n",
       "   repeticiones  longitud_tweet  letras_seguidas  sentimiento  objetividad  \n",
       "0             1              70                2      0.00000       0.0000  \n",
       "1             1              40                1      0.10000       0.4000  \n",
       "2             1             130                2     -0.01875       0.3875  \n",
       "3             1              60                1      0.00000       0.0000  \n",
       "4             1              90                2      0.00000       0.0000  \n",
       "\n",
       "[5 rows x 5014 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x=train_limpio.drop([ 'target'], axis=1)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf= RandomForestClassifier(n_estimators=50)\n",
    "#xg_reg = xgb.XGBClassifier(objective ='reg:squarederror', \n",
    "#                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xgc = xgb.XGBClassifier()\n",
    "xgc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201569694240473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test.values, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index,test_index in kf.split(train_limpio):\n",
    "    x_train,x_test = df_x.loc[train_index], df_x.loc[test_index]\n",
    "    y_train,y_test = df_y[train_index],df_y[test_index]\n",
    "    \n",
    "    xgc = xgb.XGBClassifier()\n",
    "    xgc.fit(x_train, y_train)\n",
    "    \n",
    "    #error de entrenamiento:\n",
    "    pred = xgc.predict(x_train)\n",
    "    print('Error de entrenamiento: ',f1_score(y_train.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "        \n",
    "    #error de test:\n",
    "    pred = xgc.predict(x_test)\n",
    "    print('Error de test: ',f1_score(y_test.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #x_train = train.drop['target']\n",
    "    #x_test = test.drop['target']\n",
    "    #y_train = train.target\n",
    "    #y_test = test.target\n",
    "    #print(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tunning con griddsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid={\n",
    "    'n_estimators': [50,100,150,200],\n",
    "    'learning_rate' : [0.3,0.45,0.6,0.75],\n",
    "    'max_depth' : [3,6,9,12]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fixed={\n",
    "    'objective':'binary:logistic',\n",
    "    'silent' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_grid= GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(**params_fixed),\n",
    "    param_grid=params_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = bst_grid.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dio que {'n_estimators': 100, 'learning_rate': 0.45, 'max_depth': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error de entrenamiento: ', 0.9079067742013525)\n",
      "('Error de test: ', 0.7214610030263966)\n",
      "('Error de entrenamiento: ', 0.9157659667423765)\n",
      "('Error de test: ', 0.6905816640986133)\n",
      "('Error de entrenamiento: ', 0.9158718583213232)\n",
      "('Error de test: ', 0.6711226662299378)\n",
      "('Error de entrenamiento: ', 0.911319007273595)\n",
      "('Error de test: ', 0.6778987496272846)\n",
      "('Error de entrenamiento: ', 0.9067737251228332)\n",
      "('Error de test: ', 0.7286316047234371)\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(train_sin_texto):\n",
    "    x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "    y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "    xgc = xgb.XGBClassifier(n_estimatores=100 , learning_rate=0.45 , max_depth=6)\n",
    "    xgc.fit(x_train, y_train)\n",
    "    \n",
    "    #error de entrenamiento:\n",
    "    pred = xgc.predict(x_train)\n",
    "    print('Error de entrenamiento: ',f1_score(y_train.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "        \n",
    "    #error de test:\n",
    "    pred = xgc.predict(x_test)\n",
    "    print('Error de test: ',f1_score(y_test.values, pred, average='macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La realizo devuelta con mayor precision alrededor de los puntos seleccionados antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid={\n",
    "    'n_estimators': [70,80,90,100,110,120,130],\n",
    "    'learning_rate' : [0.35,0.4,0.45,0.5,0.55],\n",
    "    'max_depth' : [1,2,3]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_grid= GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(**params_fixed),\n",
    "    param_grid=params_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=1,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [70, 80, 90, 100, 110, 120, 130], 'learning_rate': [0.35, 0.4, 0.45, 0.5, 0.55], 'max_depth': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.45, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = bst_grid.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me da lo mismo, lo dejo aca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estoy en la iteracion', 10)\n",
      "('El error total es:', 0.6389825858450193)\n",
      "\n",
      "('Estoy en la iteracion', 20)\n",
      "('El error total es:', 0.6306167861903378)\n",
      "\n",
      "('Estoy en la iteracion', 30)\n",
      "('El error total es:', 0.6291491936159268)\n",
      "\n",
      "('Estoy en la iteracion', 40)\n",
      "('El error total es:', 0.6317984843311492)\n",
      "\n",
      "('Estoy en la iteracion', 50)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-698fbe61cea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mxgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mxgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#error de test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Optimizo los \n",
    "best_score = 0\n",
    "best_n_estimators = 0\n",
    "current_score=[]\n",
    "for i in np.arange(10,200,10):\n",
    "    print('Estoy en la iteracion',i)\n",
    "    current_score = []\n",
    "    for train_index,test_index in kf.split(train_sin_texto):\n",
    "        x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "        y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "        xgc = xgb.XGBClassifier(n_estimators=i)\n",
    "        xgc.fit(x_train, y_train)\n",
    "       \n",
    "        #error de test:\n",
    "        pred = xgc.predict(x_test)\n",
    "        score = f1_score(y_test.values, pred, average='macro')\n",
    "        current_score.append(score)\n",
    "        \n",
    "    print('El error total es:', sum(current_score)/len(current_score))\n",
    "    if(sum(current_score)/len(current_score)>best_score):\n",
    "        best_score = sum(current_score)/len(current_score)\n",
    "        best_n_estimators = i\n",
    "    print('')\n",
    "    \n",
    "\n",
    "print('Termine todo y la mejor iteracion fue con n_estimators:', best_min_samples_splite)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.15000000000000002\n",
      "0.20000000000000004\n",
      "0.25000000000000006\n",
      "0.30000000000000004\n",
      "0.3500000000000001\n",
      "0.40000000000000013\n",
      "0.45000000000000007\n",
      "0.5000000000000001\n",
      "0.5500000000000002\n",
      "0.6000000000000002\n",
      "0.6500000000000001\n",
      "0.7000000000000002\n",
      "0.7500000000000002\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,0.8,0.05):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n",
      "[2, 8]\n",
      "[2, 10]\n"
     ]
    }
   ],
   "source": [
    "x=[[2,4],[2,8],[2,10]]\n",
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estoy en la iteracion', 0.1)\n",
      "('El error total es:', 0.6696071409718021)\n",
      "\n",
      "('Estoy en la iteracion', 0.15000000000000002)\n",
      "('El error total es:', 0.6840317020076526)\n",
      "\n",
      "('Estoy en la iteracion', 0.20000000000000004)\n",
      "('El error total es:', 0.6948791612358646)\n",
      "\n",
      "('Estoy en la iteracion', 0.25000000000000006)\n",
      "('El error total es:', 0.6980475826294187)\n",
      "\n",
      "('Estoy en la iteracion', 0.30000000000000004)\n",
      "('El error total es:', 0.7024620105294133)\n",
      "\n",
      "('Estoy en la iteracion', 0.3500000000000001)\n",
      "('El error total es:', 0.7003358039716753)\n",
      "\n",
      "('Estoy en la iteracion', 0.40000000000000013)\n",
      "('El error total es:', 0.7033887830346475)\n",
      "\n",
      "('Estoy en la iteracion', 0.45000000000000007)\n",
      "('El error total es:', 0.7023512591389872)\n",
      "\n",
      "('Estoy en la iteracion', 0.5000000000000001)\n",
      "('El error total es:', 0.7001311519196041)\n",
      "\n",
      "('Estoy en la iteracion', 0.5500000000000002)\n",
      "('El error total es:', 0.7067419362383354)\n",
      "\n",
      "('Estoy en la iteracion', 0.6000000000000002)\n",
      "('El error total es:', 0.70740219669265)\n",
      "\n",
      "('Estoy en la iteracion', 0.6500000000000001)\n",
      "('El error total es:', 0.7040683437763862)\n",
      "\n",
      "('Estoy en la iteracion', 0.7000000000000002)\n",
      "('El error total es:', 0.701342234598513)\n",
      "\n",
      "('Estoy en la iteracion', 0.7500000000000002)\n",
      "('El error total es:', 0.7012475619709306)\n",
      "\n",
      "('Termine todo y la mejor iteracion fue con learning_rate:', 0)\n"
     ]
    }
   ],
   "source": [
    "#Optimizo los \n",
    "best_score = 0\n",
    "best_learning_rate = 0\n",
    "current_score=[]\n",
    "for i in np.arange(0.1,0.8,0.05):\n",
    "    print('Estoy en la iteracion',i)\n",
    "    current_score = []\n",
    "    for train_index,test_index in kf.split(train_sin_texto):\n",
    "        x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "        y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "        xgc = xgb.XGBClassifier(n_estimators=170, learning_rate=i)\n",
    "        xgc.fit(x_train, y_train)\n",
    "       \n",
    "        #error de test:\n",
    "        pred = xgc.predict(x_test)\n",
    "        score = f1_score(y_test.values, pred, average='macro')\n",
    "        current_score.append(score)\n",
    "        \n",
    "    print('El error total es:', sum(current_score)/len(current_score))\n",
    "    if(sum(current_score)/len(current_score)>best_score):\n",
    "        best_score = sum(current_score)/len(current_score)\n",
    "        best_n_estimators = i\n",
    "    print('')\n",
    "    \n",
    "\n",
    "print('Termine todo y la mejor iteracion fue con learning_rate:', best_learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estoy en la iteracion', 1)\n",
      "('El error total es:', 0.6920187769437961)\n",
      "\n",
      "('Estoy en la iteracion', 2)\n",
      "('El error total es:', 0.7032492023962751)\n",
      "\n",
      "('Estoy en la iteracion', 3)\n",
      "('El error total es:', 0.70740219669265)\n",
      "\n",
      "('Estoy en la iteracion', 4)\n",
      "('El error total es:', 0.7011707542672008)\n",
      "\n",
      "('Estoy en la iteracion', 5)\n",
      "('El error total es:', 0.7036782855604653)\n",
      "\n",
      "('Termine todo y la mejor iteracion fue con best_max_depth:', 3)\n"
     ]
    }
   ],
   "source": [
    "#Optimizo los \n",
    "best_score = 0\n",
    "best_max_depth = 0\n",
    "current_score=[]\n",
    "for i in np.arange(1,6,1):\n",
    "    print('Estoy en la iteracion',i)\n",
    "    current_score = []\n",
    "    for train_index,test_index in kf.split(train_sin_texto):\n",
    "        x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "        y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "        xgc = xgb.XGBClassifier(n_estimators=170,learning_rate=0.6 ,max_depth=i)\n",
    "        xgc.fit(x_train, y_train)\n",
    "       \n",
    "        #error de test:\n",
    "        pred = xgc.predict(x_test)\n",
    "        score = f1_score(y_test.values, pred, average='macro')\n",
    "        current_score.append(score)\n",
    "        \n",
    "    print('El error total es:', sum(current_score)/len(current_score))\n",
    "    if(sum(current_score)/len(current_score)>best_score):\n",
    "        best_score = sum(current_score)/len(current_score)\n",
    "        best_max_depth = i\n",
    "    print('')\n",
    "    \n",
    "\n",
    "print('Termine todo y la mejor iteracion fue con best_max_depth:', best_max_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estoy en la iteracion', 0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9c574dca2570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mxgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mxgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#error de test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Optimizo los \n",
    "best_score = 0\n",
    "best_colsample_bylevel = 0\n",
    "current_score=[]\n",
    "for i in np.arange(0,6,1):\n",
    "    print('Estoy en la iteracion',i)\n",
    "    current_score = []\n",
    "    for train_index,test_index in kf.split(train_sin_texto):\n",
    "        x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "        y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "        xgc = xgb.XGBClassifier(n_estimators=170,learning_rate=0.6, reg_alpha=i)\n",
    "        xgc.fit(x_train, y_train)\n",
    "       \n",
    "        #error de test:\n",
    "        pred = xgc.predict(x_test)\n",
    "        score = f1_score(y_test.values, pred, average='macro')\n",
    "        current_score.append(score)\n",
    "        \n",
    "    print('El error total es:', sum(current_score)/len(current_score))\n",
    "    if(sum(current_score)/len(current_score)>best_score):\n",
    "        best_score = sum(current_score)/len(current_score)\n",
    "        best_colsample_bylevel = i\n",
    "    print('')\n",
    "    \n",
    "\n",
    "print('Termine todo y la mejor iteracion fue con best_colsample_bylevel:', best_colsample_bylevel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error de entrenamiento: ', 0.990690743566668)\n",
      "('Error de test: ', 0.7126520059491375)\n",
      "('Error de entrenamiento: ', 0.9893737281175179)\n",
      "('Error de test: ', 0.6882951846416847)\n",
      "('Error de entrenamiento: ', 0.991220004243921)\n",
      "('Error de test: ', 0.6642129800024537)\n",
      "('Error de entrenamiento: ', 0.9911884059613871)\n",
      "('Error de test: ', 0.6860695341845173)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-33609b878d28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#error de entrenamiento:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andres/.local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(train_sin_texto):\n",
    "    x_train,x_test = train_sin_texto.drop(['target'], axis=1).loc[train_index], train_sin_texto.drop([ 'target'], axis=1).loc[test_index]\n",
    "    y_train,y_test = train_sin_texto.target[train_index], train_sin_texto.target[test_index]\n",
    "    \n",
    "    xgc = xgb.XGBClassifier(n_estimators=170,learning_rate=0.6, max_depth=300)\n",
    "    xgc.fit(x_train, y_train)\n",
    "    \n",
    "    #error de entrenamiento:\n",
    "    pred = xgc.predict(x_train)\n",
    "    print('Error de entrenamiento: ',f1_score(y_train.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "        \n",
    "    #error de test:\n",
    "    pred = xgc.predict(x_test)\n",
    "    print('Error de test: ',f1_score(y_test.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #x_train = train.drop['target']\n",
    "    #x_test = test.drop['target']\n",
    "    #y_train = train.target\n",
    "    #y_test = test.target\n",
    "    #print(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('Error de entrenamiento: ', 0.8789356902689002)\n",
    "('Error de test: ', 0.723091447415077)\n",
    "('Error de entrenamiento: ', 0.881829835892072)\n",
    "('Error de test: ', 0.6897637409283246)\n",
    "('Error de entrenamiento: ', 0.8907643748505321)\n",
    "('Error de test: ', 0.6885271323347347)\n",
    "('Error de entrenamiento: ', 0.8769172774750192)\n",
    "('Error de test: ', 0.6882782122416882)\n",
    "('Error de entrenamiento: ', 0.875463532895278)\n",
    "('Error de test: ', 0.7353115751465339)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error de entrenamiento: ', 0.8218694822450909)\n"
     ]
    }
   ],
   "source": [
    "# Entonces, mi modelo optimizado es:\n",
    "train_x=train_limpio.drop(['text', 'target'], axis=1)\n",
    "\n",
    "train_y=train_limpio.target\n",
    "\n",
    "\n",
    "\n",
    "xgc = xgb.XGBClassifier(n_estimators=170,learning_rate=0.6)\n",
    "xgc.fit(train_x, train_y)\n",
    "    \n",
    "#error de entrenamiento, es el unico que puedo calcular:\n",
    "pred = xgc.predict(train_x)\n",
    "print('Error de entrenamiento: ',f1_score(train_y, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgc.predict(test_limpio_sin_texto.drop(['id'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediccion_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
