{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\",encoding = \"ISO-8859-1\")\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abil</th>\n",
       "      <th>...</th>\n",
       "      <th>money_related</th>\n",
       "      <th>tiene_fecha</th>\n",
       "      <th>has_year</th>\n",
       "      <th>tiene_hora</th>\n",
       "      <th>tiene_hora_2</th>\n",
       "      <th>repeticiones</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abil  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   money_related  tiene_fecha  has_year  tiene_hora  tiene_hora_2  \\\n",
       "0          False        False     False       False         False   \n",
       "1          False        False     False       False         False   \n",
       "\n",
       "   repeticiones  longitud_tweet  letras_seguidas  sentimiento  objetividad  \n",
       "0             1              70                2          0.0          0.0  \n",
       "1             1              40                1          0.1          0.4  \n",
       "\n",
       "[2 rows x 5014 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_limpio = pd.read_csv(\"train_limpio_con_BOW_de_5000_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "train_limpio.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abil</th>\n",
       "      <th>...</th>\n",
       "      <th>money_related</th>\n",
       "      <th>tiene_fecha</th>\n",
       "      <th>has_year</th>\n",
       "      <th>tiene_hora</th>\n",
       "      <th>tiene_hora_2</th>\n",
       "      <th>repeticiones</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abil  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "2   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "3   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "4   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   money_related  tiene_fecha  has_year  tiene_hora  tiene_hora_2  \\\n",
       "0          False        False     False       False         False   \n",
       "1          False        False     False       False         False   \n",
       "2          False        False     False       False         False   \n",
       "3          False        False     False       False         False   \n",
       "4          False        False     False       False         False   \n",
       "\n",
       "   repeticiones  longitud_tweet  letras_seguidas  sentimiento  objetividad  \n",
       "0             1              40                2        -1.00         1.00  \n",
       "1             1              70                2         0.25         0.55  \n",
       "2             1             100                2         0.00         0.00  \n",
       "3             1              40                1         0.00         0.00  \n",
       "4             1              50                2         0.00         0.00  \n",
       "\n",
       "[5 rows x 5013 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_limpio = pd.read_csv(\"test_limpio_con_BOW_de_5000_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "test_limpio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y=train_limpio.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio_normalizado = train_limpio.drop(columns = ['target']).values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(train_limpio_normalizado)\n",
    "train_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_limpio_normalizado = test_limpio.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(test_limpio_normalizado)\n",
    "test_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_limpio_normalizado, train_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 74.29034874290348 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "print(f\"Model Score: {f1score * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489585518626187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341602661181936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7561643715770502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7334130338078292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749771720129098\n",
      "iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7471238813530703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7325990186944229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7553796982230989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7366206932290973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768584676529036\n",
      "iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7471238813530703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7332068172694428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539660754273405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735820027133123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "iter\n",
      "0.7471238813530703\n",
      "0.7332068172694428\n",
      "0.7539660754273405\n",
      "0.735820027133123\n",
      "0.7769479051897054\n",
      "Con max_iter= 30  se tuvo un error de :  0.7495346790757204\n",
      "Con max_iter= 50  se tuvo un error de :  0.7497163518305185\n",
      "Con max_iter= 70  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 100  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 200  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 300  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 500  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 700  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 1000  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 1500  se tuvo un error de :  0.7494129412745364\n",
      "Con max_iter= 3000  se tuvo un error de :  0.7494129412745364\n"
     ]
    }
   ],
   "source": [
    "total_error=[]\n",
    "test_error=[]\n",
    "\n",
    "valores_max_iter = [30,50,70,100,200,300,500,700,1000,1500,3000]\n",
    "for i in valores_max_iter:\n",
    "    test_error=[]\n",
    "    print('iter')\n",
    "    for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "        x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "        y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "        model = LogisticRegression(max_iter=i)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        #error de test:\n",
    "        pred = model.predict(x_test)\n",
    "        test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "    \n",
    "    total_error.append(np.mean(test_error))\n",
    "\n",
    "for i in range(len(valores_max_iter)):\n",
    "    print('Con max_iter=',valores_max_iter[i],' se tuvo un error de : ',total_error[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mejor es con 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(train_limpio_normalizado, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_limpio_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediccion_Linear_regression_features_normalizados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(importance.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiroshima',\n",
       " 'wild',\n",
       " 'earthquak',\n",
       " 'type',\n",
       " 'storm',\n",
       " 'massacr',\n",
       " 'debri',\n",
       " 'tori',\n",
       " 'spill',\n",
       " 'drought',\n",
       " 'awar',\n",
       " 'hailstorm',\n",
       " 'explos',\n",
       " 'murder',\n",
       " 'evacu',\n",
       " 'flood',\n",
       " 'terrifi',\n",
       " 'outbreak',\n",
       " 'fire',\n",
       " 'casualti',\n",
       " 'suicid',\n",
       " 'Ã¢v',\n",
       " 'trailer',\n",
       " 'voic',\n",
       " 'collis',\n",
       " 'riot',\n",
       " 'migrant',\n",
       " 'sever',\n",
       " 'incid',\n",
       " 'distanc',\n",
       " 'hurrican',\n",
       " 'confirm',\n",
       " 'wife',\n",
       " 'california',\n",
       " 'derail',\n",
       " 'tiene_hora_2',\n",
       " 'vigil',\n",
       " 'buse',\n",
       " 'horribl',\n",
       " 'afternoon',\n",
       " 'apt',\n",
       " 'disast',\n",
       " 'vicin',\n",
       " 'near',\n",
       " 'east',\n",
       " 'bridg',\n",
       " 'palestinian',\n",
       " 'grate',\n",
       " 'crew',\n",
       " 'gas']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model.coef_\n",
    "\n",
    "def Nmaxelements(list1,valores, N): \n",
    "    final_list = [] \n",
    "    final_values = []\n",
    "\n",
    "    for i in range(0, N):  \n",
    "        max1 = 0\n",
    "        value = 0\n",
    "          \n",
    "        for j in range(len(list1)):      \n",
    "            if list1[j] > max1: \n",
    "                #print(j)\n",
    "                max1 = list1[j]; \n",
    "                value = valores[j]\n",
    "                  \n",
    "        valores.remove(value)\n",
    "        final_values.append(value)\n",
    "        \n",
    "        \n",
    "        list1.remove(max1); \n",
    "        final_list.append(max1) \n",
    "           \n",
    "    return([final_list,final_values])\n",
    "  \n",
    "# Driver code \n",
    "N = 50\n",
    "  \n",
    "# Calling the function \n",
    "values_best_features,best_feaures = Nmaxelements(importance.tolist()[0],list(train_limpio.columns), N) \n",
    "best_feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  hiroshima\n",
      "j:  hiroshima\n",
      "j:  wild\n",
      "j:  earthquak\n",
      "i:  wild\n",
      "j:  hiroshima\n",
      "j:  wild\n",
      "j:  earthquak\n",
      "i:  earthquak\n",
      "j:  hiroshima\n",
      "j:  wild\n",
      "j:  earthquak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' El promedio sin ', 'hiroshima', 'hiroshima', 'es : ', 0.797129396198752),\n",
       " (' El promedio sin ', 'wild', 'hiroshima', 'es : ', 0.8060770375063278),\n",
       " (' El promedio sin ', 'earthquak', 'hiroshima', 'es : ', 0.8015164011982676),\n",
       " (' El promedio sin ', 'hiroshima', 'wild', 'es : ', 0.7769404595500959),\n",
       " (' El promedio sin ', 'wild', 'wild', 'es : ', 0.8002205157658137),\n",
       " (' El promedio sin ', 'earthquak', 'wild', 'es : ', 0.7802170912285105),\n",
       " (' El promedio sin ', 'hiroshima', 'earthquak', 'es : ', 0.7959757796592006),\n",
       " (' El promedio sin ', 'wild', 'earthquak', 'es : ', 0.7926277995991187),\n",
       " (' El promedio sin ', 'earthquak', 'earthquak', 'es : ', 0.7990150019531044)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features=['hiroshima','wild','earthquak']\n",
    "\n",
    "#train_limpio = train_limpio.drop(columns=['target'])\n",
    "\n",
    "resultados = []\n",
    "for i in top_features:\n",
    "\n",
    "    train_sin_un_feature = train_limpio.drop(columns = [i])\n",
    "    print('i: ',i)\n",
    "    for j in top_features:\n",
    "        print('j: ',j)\n",
    "        if(j!=i):\n",
    "            train_sin_dos_features = train_sin_un_feature.drop(columns = [j])\n",
    "        else:\n",
    "            train_sin_dos_features = train_sin_un_feature\n",
    "            \n",
    "        train_limpio_normalizado = train_sin_dos_features.values\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(train_limpio_normalizado)\n",
    "        train_limpio_normalizado = pd.DataFrame(x_scaled)\n",
    "            \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(train_limpio_normalizado, train_y, test_size=0.2)\n",
    "        \n",
    "        model = LogisticRegression(max_iter=100)\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        pred = model.predict(x_test)\n",
    "        resultados.append((' El promedio sin ',j ,i, 'es : ',f1_score(y_test.values, pred, average='macro')))\n",
    "        \n",
    "    \n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que da un poco mejor si remuevo 'wild' e 'hiroshima'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sin_dos_features = train_limpio.drop(columns = ['wild','hiroshima'])\n",
    "train_limpio_normalizado = train_sin_dos_features.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(train_limpio_normalizado)\n",
    "train_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7498839979421781"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error =[]\n",
    "\n",
    "for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "    x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "    y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "        #error de test:\n",
    "    pred = model.predict(x_test)\n",
    "    test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "    \n",
    "np.mean(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da un poco mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(train_limpio_normalizado, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_limpio_sin_dos_features = test_limpio.drop(columns = ['wild','hiroshima'])\n",
    "test_limpio_normalizado = test_limpio_sin_dos_features.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(test_limpio_normalizado)\n",
    "test_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_limpio_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediccion_Linear_regression_features_normalizados_y_algunos_removidos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaaa'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
