{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio = pd.read_csv(\"train_limpio_con_BOW_de_5000_y_Stemming_noDrops.csv\",encoding = \"ISO-8859-1\")\n",
    "test_limpio = pd.read_csv(\"test_limpio_con_BOW_de_5000_y_Stemming_noDrops.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio[\"text\"] = train_limpio[\"text\"].map(lambda x : \"null\" if(x is None) else x)\n",
    "test_limpio[\"text\"] = test_limpio[\"text\"].map(lambda x : \"null\" if(x is None) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio_true = train_limpio.loc[train_limpio[\"target\"] == 1].sample(frac=1).reset_index(drop=True)\n",
    "train_limpio_false = train_limpio.loc[train_limpio[\"target\"] == 0].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos  3271.00 verdaderos y  4342.00 falsos\n"
     ]
    }
   ],
   "source": [
    "print(\"Tenemos {cant_verdaderos: .2f} verdaderos y {cant_falsos: .2f} falsos\".format(cant_verdaderos=len(train_limpio_true), cant_falsos=len(train_limpio_false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voy a balancear el train y el validation, misma cantidad de falsos y verdaderos en ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_limpio_true.iloc[:2616], train_limpio_false.iloc[:3473]])\n",
    "val = pd.concat([train_limpio_true.iloc[2616:3000], train_limpio_false.iloc[3473:3850]])\n",
    "test = pd.concat([train_limpio_true.iloc[3000:], train_limpio_false.iloc[3850:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abe</th>\n",
       "      <th>abil</th>\n",
       "      <th>...</th>\n",
       "      <th>wound-keyword</th>\n",
       "      <th>wreck-keyword</th>\n",
       "      <th>wreckag-keyword</th>\n",
       "      <th>isRealPlace</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>cyclon</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>trauma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 5184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  aba  abandon  abbott  abbswinston  abc  abcnew  abe  abil  ...  \\\n",
       "0   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "1   0   0    0        0       0            0    0       0    0     0  ...   \n",
       "\n",
       "   wound-keyword  wreck-keyword  wreckag-keyword  isRealPlace  longitud_tweet  \\\n",
       "0          False          False            False         True              90   \n",
       "1          False          False            False        False             110   \n",
       "\n",
       "   letras_seguidas  sentimiento  objetividad  keyword     location  \n",
       "0                2     0.118182     0.427273   cyclon  Philippines  \n",
       "1                1     0.500000     0.500000   trauma          NaN  \n",
       "\n",
       "[2 rows x 5184 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_limpio[\"text\"].values.astype('U'))\n",
    "\n",
    "X_train = vectorizer.transform(train[\"text\"].values.astype('U'))\n",
    "X_val  = vectorizer.transform(val[\"text\"].values.astype('U'))\n",
    "X_test = vectorizer.transform(test[\"text\"].values.astype('U'))\n",
    "\n",
    "actual_tp_test_only_text = vectorizer.transform(test_limpio[\"text\"].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer modelo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                133800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 133,811\n",
      "Trainable params: 133,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7674 - val_loss: 0.4723 - val_accuracy: 0.7924\n",
      "Epoch 2/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.3385 - accuracy: 0.8706 - val_loss: 0.4614 - val_accuracy: 0.8029\n",
      "Epoch 3/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.2342 - accuracy: 0.9157 - val_loss: 0.4795 - val_accuracy: 0.7937\n",
      "Epoch 4/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.1698 - accuracy: 0.9414 - val_loss: 0.5282 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9565 - val_loss: 0.5745 - val_accuracy: 0.7714\n",
      "Epoch 6/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.1029 - accuracy: 0.9639 - val_loss: 0.6309 - val_accuracy: 0.7700\n",
      "Epoch 7/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.6754 - val_accuracy: 0.7661\n",
      "Epoch 8/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0762 - accuracy: 0.9713 - val_loss: 0.7349 - val_accuracy: 0.7661\n",
      "Epoch 9/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0674 - accuracy: 0.9719 - val_loss: 0.7784 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0631 - accuracy: 0.9734 - val_loss: 0.8134 - val_accuracy: 0.7700\n",
      "Epoch 11/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0591 - accuracy: 0.9755 - val_loss: 0.8574 - val_accuracy: 0.7661\n",
      "Epoch 12/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0561 - accuracy: 0.9757 - val_loss: 0.9107 - val_accuracy: 0.7635\n",
      "Epoch 13/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0542 - accuracy: 0.9767 - val_loss: 0.9447 - val_accuracy: 0.7674\n",
      "Epoch 14/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0498 - accuracy: 0.9800 - val_loss: 0.9861 - val_accuracy: 0.7490\n",
      "Epoch 15/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0512 - accuracy: 0.9775 - val_loss: 1.0132 - val_accuracy: 0.7608\n",
      "Epoch 16/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0486 - accuracy: 0.9788 - val_loss: 1.0456 - val_accuracy: 0.7451\n",
      "Epoch 17/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0477 - accuracy: 0.9801 - val_loss: 1.0720 - val_accuracy: 0.7543\n",
      "Epoch 18/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0480 - accuracy: 0.9785 - val_loss: 1.1156 - val_accuracy: 0.7556\n",
      "Epoch 19/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0466 - accuracy: 0.9806 - val_loss: 1.1485 - val_accuracy: 0.7477\n",
      "Epoch 20/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0452 - accuracy: 0.9818 - val_loss: 1.1754 - val_accuracy: 0.7503\n",
      "Epoch 21/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0458 - accuracy: 0.9809 - val_loss: 1.2088 - val_accuracy: 0.7424\n",
      "Epoch 22/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0433 - accuracy: 0.9816 - val_loss: 1.2579 - val_accuracy: 0.7398\n",
      "Epoch 23/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0417 - accuracy: 0.9829 - val_loss: 1.2814 - val_accuracy: 0.7372\n",
      "Epoch 24/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9813 - val_loss: 1.3143 - val_accuracy: 0.7372\n",
      "Epoch 25/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.9813 - val_loss: 1.3224 - val_accuracy: 0.7490\n",
      "Epoch 26/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0426 - accuracy: 0.9798 - val_loss: 1.3555 - val_accuracy: 0.7451\n",
      "Epoch 27/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0423 - accuracy: 0.9808 - val_loss: 1.3915 - val_accuracy: 0.7319\n",
      "Epoch 28/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0423 - accuracy: 0.9795 - val_loss: 1.4249 - val_accuracy: 0.7411\n",
      "Epoch 29/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0399 - accuracy: 0.9813 - val_loss: 1.4381 - val_accuracy: 0.7438\n",
      "Epoch 30/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0417 - accuracy: 0.9803 - val_loss: 1.4706 - val_accuracy: 0.7424\n",
      "Epoch 31/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0405 - accuracy: 0.9809 - val_loss: 1.4939 - val_accuracy: 0.7451\n",
      "Epoch 32/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0393 - accuracy: 0.9821 - val_loss: 1.5297 - val_accuracy: 0.7438\n",
      "Epoch 33/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0395 - accuracy: 0.9819 - val_loss: 1.5356 - val_accuracy: 0.7438\n",
      "Epoch 34/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0397 - accuracy: 0.9814 - val_loss: 1.5628 - val_accuracy: 0.7372\n",
      "Epoch 35/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0397 - accuracy: 0.9795 - val_loss: 1.5759 - val_accuracy: 0.7451\n",
      "Epoch 36/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9796 - val_loss: 1.6035 - val_accuracy: 0.7372\n",
      "Epoch 37/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0382 - accuracy: 0.9805 - val_loss: 1.6278 - val_accuracy: 0.7346\n",
      "Epoch 38/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0387 - accuracy: 0.9821 - val_loss: 1.6426 - val_accuracy: 0.7346\n",
      "Epoch 39/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0370 - accuracy: 0.9823 - val_loss: 1.6665 - val_accuracy: 0.7385\n",
      "Epoch 40/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.9813 - val_loss: 1.6873 - val_accuracy: 0.7346\n",
      "Epoch 41/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0377 - accuracy: 0.9819 - val_loss: 1.6977 - val_accuracy: 0.7385\n",
      "Epoch 42/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0365 - accuracy: 0.9824 - val_loss: 1.7084 - val_accuracy: 0.7372\n",
      "Epoch 43/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0367 - accuracy: 0.9813 - val_loss: 1.7235 - val_accuracy: 0.7359\n",
      "Epoch 44/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.9813 - val_loss: 1.7422 - val_accuracy: 0.7359\n",
      "Epoch 45/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0364 - accuracy: 0.9813 - val_loss: 1.7466 - val_accuracy: 0.7346\n",
      "Epoch 46/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0354 - accuracy: 0.9826 - val_loss: 1.7703 - val_accuracy: 0.7385\n",
      "Epoch 47/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0355 - accuracy: 0.9818 - val_loss: 1.7856 - val_accuracy: 0.7359\n",
      "Epoch 48/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0357 - accuracy: 0.9823 - val_loss: 1.7891 - val_accuracy: 0.7332\n",
      "Epoch 49/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0353 - accuracy: 0.9823 - val_loss: 1.8063 - val_accuracy: 0.7293\n",
      "Epoch 50/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9826 - val_loss: 1.8061 - val_accuracy: 0.7332\n",
      "Epoch 51/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9832 - val_loss: 1.8123 - val_accuracy: 0.7293\n",
      "Epoch 52/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9821 - val_loss: 1.8165 - val_accuracy: 0.7346\n",
      "Epoch 53/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0345 - accuracy: 0.9818 - val_loss: 1.8307 - val_accuracy: 0.7319\n",
      "Epoch 54/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9818 - val_loss: 1.8229 - val_accuracy: 0.7332\n",
      "Epoch 55/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0340 - accuracy: 0.9828 - val_loss: 1.8313 - val_accuracy: 0.7280\n",
      "Epoch 56/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0337 - accuracy: 0.9831 - val_loss: 1.8511 - val_accuracy: 0.7306\n",
      "Epoch 57/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9819 - val_loss: 1.8622 - val_accuracy: 0.7346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0346 - accuracy: 0.9828 - val_loss: 1.8425 - val_accuracy: 0.7332\n",
      "Epoch 59/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0339 - accuracy: 0.9814 - val_loss: 1.8462 - val_accuracy: 0.7332\n",
      "Epoch 60/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0340 - accuracy: 0.9823 - val_loss: 1.8567 - val_accuracy: 0.7293\n",
      "Epoch 61/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0333 - accuracy: 0.9826 - val_loss: 1.8582 - val_accuracy: 0.7267\n",
      "Epoch 62/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0333 - accuracy: 0.9824 - val_loss: 1.8632 - val_accuracy: 0.7293\n",
      "Epoch 63/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0334 - accuracy: 0.9821 - val_loss: 1.8652 - val_accuracy: 0.7280\n",
      "Epoch 64/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.9826 - val_loss: 1.8768 - val_accuracy: 0.7359\n",
      "Epoch 65/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0327 - accuracy: 0.9832 - val_loss: 1.8636 - val_accuracy: 0.7240\n",
      "Epoch 66/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0332 - accuracy: 0.9819 - val_loss: 1.8696 - val_accuracy: 0.7346\n",
      "Epoch 67/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0330 - accuracy: 0.9829 - val_loss: 1.8749 - val_accuracy: 0.7293\n",
      "Epoch 68/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0327 - accuracy: 0.9826 - val_loss: 1.8946 - val_accuracy: 0.7293\n",
      "Epoch 69/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0326 - accuracy: 0.9823 - val_loss: 1.8924 - val_accuracy: 0.7254\n",
      "Epoch 70/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0324 - accuracy: 0.9831 - val_loss: 1.8929 - val_accuracy: 0.7359\n",
      "Epoch 71/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0330 - accuracy: 0.9819 - val_loss: 1.8714 - val_accuracy: 0.7280\n",
      "Epoch 72/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0322 - accuracy: 0.9824 - val_loss: 1.8662 - val_accuracy: 0.7319\n",
      "Epoch 73/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0322 - accuracy: 0.9829 - val_loss: 1.8924 - val_accuracy: 0.7319\n",
      "Epoch 74/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9834 - val_loss: 1.9057 - val_accuracy: 0.7398\n",
      "Epoch 75/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 1.8791 - val_accuracy: 0.7227\n",
      "Epoch 76/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0320 - accuracy: 0.9824 - val_loss: 1.9018 - val_accuracy: 0.7385\n",
      "Epoch 77/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9829 - val_loss: 1.9026 - val_accuracy: 0.7346\n",
      "Epoch 78/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 1.9074 - val_accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 1.9084 - val_accuracy: 0.7319\n",
      "Epoch 80/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0314 - accuracy: 0.9819 - val_loss: 1.9171 - val_accuracy: 0.7280\n",
      "Epoch 81/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0318 - accuracy: 0.9823 - val_loss: 1.9028 - val_accuracy: 0.7240\n",
      "Epoch 82/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9826 - val_loss: 1.9315 - val_accuracy: 0.7346\n",
      "Epoch 83/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9823 - val_loss: 1.9250 - val_accuracy: 0.7306\n",
      "Epoch 84/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9831 - val_loss: 1.9647 - val_accuracy: 0.7346\n",
      "Epoch 85/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0312 - accuracy: 0.9831 - val_loss: 1.9604 - val_accuracy: 0.7332\n",
      "Epoch 86/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9836 - val_loss: 1.9468 - val_accuracy: 0.7346\n",
      "Epoch 87/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9823 - val_loss: 1.9600 - val_accuracy: 0.7332\n",
      "Epoch 88/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9834 - val_loss: 1.9517 - val_accuracy: 0.7214\n",
      "Epoch 89/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9844 - val_loss: 1.9539 - val_accuracy: 0.7267\n",
      "Epoch 90/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0308 - accuracy: 0.9823 - val_loss: 1.9730 - val_accuracy: 0.7332\n",
      "Epoch 91/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0308 - accuracy: 0.9834 - val_loss: 1.9749 - val_accuracy: 0.7332\n",
      "Epoch 92/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0306 - accuracy: 0.9826 - val_loss: 1.9753 - val_accuracy: 0.7293\n",
      "Epoch 93/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9831 - val_loss: 1.9902 - val_accuracy: 0.7306\n",
      "Epoch 94/100\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.0305 - accuracy: 0.9834 - val_loss: 2.0091 - val_accuracy: 0.7346\n",
      "Epoch 95/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0306 - accuracy: 0.9828 - val_loss: 2.0150 - val_accuracy: 0.7359\n",
      "Epoch 96/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0302 - accuracy: 0.9839 - val_loss: 2.0133 - val_accuracy: 0.7267\n",
      "Epoch 97/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 1.9998 - val_accuracy: 0.7267\n",
      "Epoch 98/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0302 - accuracy: 0.9826 - val_loss: 2.0206 - val_accuracy: 0.7280\n",
      "Epoch 99/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0304 - accuracy: 0.9829 - val_loss: 2.0075 - val_accuracy: 0.7254\n",
      "Epoch 100/100\n",
      "609/609 [==============================] - 1s 1ms/step - loss: 0.0302 - accuracy: 0.9824 - val_loss: 2.0240 - val_accuracy: 0.7293\n"
     ]
    }
   ],
   "source": [
    "first_history = model.fit(X_train, train[\"target\"].to_numpy(),\n",
    "                    epochs=100,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_val, val[\"target\"].to_numpy()),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-4cc30225941a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-243-b8f9387078b8>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plot_history(first_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.7510\n",
      "Testing Accuracy:  0.9860\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, test[\"target\"].to_numpy(), verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPredictions = list(map(lambda x: x[0], model.predict_classes(actual_tp_test_only_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPredictionsDF = pd.DataFrame(data={'id': test_limpio[\"id\"], 'target': firstPredictions})\n",
    "firstPredictionsDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPredictionsDF.to_csv('NN_predictions_first_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo modelo, agrego ciudades y Tokenizer en vez de count para las words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Birmingham', 'Est. September 2012 - Bristol', 'AFRICA', ...,\n",
       "       'Vancouver', 'UK', 'Lincoln'], dtype=object)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_null_locations = train_limpio[train_limpio.location.notnull()][\"location\"].to_numpy()\n",
    "non_null_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5080"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "locations = encoder.fit_transform(non_null_locations)\n",
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "locations = locations.reshape((5080, 1))\n",
    "encoder.fit_transform(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all resid ask to shelter in place are be notifi by offic no other evacu or shelter in place order are expect\n",
      "[404, 671, 228, 27, 20, 325, 210, 248, 6, 1, 93, 5, 212, 67, 73]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_limpio[\"text\"].values.astype('U'))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train[\"text\"].values.astype('U'))\n",
    "X_val = tokenizer.texts_to_sequences(val[\"text\"].values.astype('U'))\n",
    "X_test = tokenizer.texts_to_sequences(test[\"text\"].values.astype('U'))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(train_limpio[\"text\"].values[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 280\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo sin ciudades, solo texto, modelo max complejo con maxPooling y mejor embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 280, 50)           675500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 676,021\n",
      "Trainable params: 676,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model1.add(layers.GlobalMaxPool1D())\n",
    "model1.add(layers.Dense(10, activation='relu'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.7588\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-2a6fff767eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:  {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-243-b8f9387078b8>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "second_history = model1.fit(X_train, train[\"target\"].to_numpy(),\n",
    "                    epochs=50,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_val, val[\"target\"].to_numpy()),\n",
    "                    batch_size=10)\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_test, test[\"target\"].to_numpy(), verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
