{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\",encoding = \"ISO-8859-1\")\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abl</th>\n",
       "      <th>ablaz</th>\n",
       "      <th>about</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>abstorm</th>\n",
       "      <th>...</th>\n",
       "      <th>wildfir-keyword</th>\n",
       "      <th>windstorm-keyword</th>\n",
       "      <th>wound-keyword</th>\n",
       "      <th>wreck-keyword</th>\n",
       "      <th>wreckag-keyword</th>\n",
       "      <th>isRealPlace</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abandon  abc  abcnew  abl  ablaz  about  abov  absolut  abstorm  ...  \\\n",
       "0    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "1    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "\n",
       "   wildfir-keyword  windstorm-keyword  wound-keyword  wreck-keyword  \\\n",
       "0            False              False          False          False   \n",
       "1            False              False          False          False   \n",
       "\n",
       "   wreckag-keyword  isRealPlace  longitud_tweet  letras_seguidas  sentimiento  \\\n",
       "0            False        False              70                2          0.0   \n",
       "1            False        False              40                1          0.1   \n",
       "\n",
       "   objetividad  \n",
       "0          0.0  \n",
       "1          0.4  \n",
       "\n",
       "[2 rows x 2732 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_limpio = pd.read_csv(\"train_limpio_con_BOW_de_2500_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "train_limpio.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>abl</th>\n",
       "      <th>ablaz</th>\n",
       "      <th>about</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>abstorm</th>\n",
       "      <th>...</th>\n",
       "      <th>wildfir-keyword</th>\n",
       "      <th>windstorm-keyword</th>\n",
       "      <th>wound-keyword</th>\n",
       "      <th>wreck-keyword</th>\n",
       "      <th>wreckag-keyword</th>\n",
       "      <th>isRealPlace</th>\n",
       "      <th>longitud_tweet</th>\n",
       "      <th>letras_seguidas</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>objetividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abandon  abc  abcnew  abl  ablaz  about  abov  absolut  abstorm  ...  \\\n",
       "0    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "1    0        0    0       0    0      0      1     0        0        0  ...   \n",
       "2    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "3    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "4    0        0    0       0    0      0      0     0        0        0  ...   \n",
       "\n",
       "   wildfir-keyword  windstorm-keyword  wound-keyword  wreck-keyword  \\\n",
       "0            False              False          False          False   \n",
       "1            False              False          False          False   \n",
       "2            False              False          False          False   \n",
       "3            False              False          False          False   \n",
       "4            False              False          False          False   \n",
       "\n",
       "   wreckag-keyword  isRealPlace  longitud_tweet  letras_seguidas  sentimiento  \\\n",
       "0            False        False              40                2        -1.00   \n",
       "1            False        False              70                2         0.25   \n",
       "2            False        False             100                2         0.00   \n",
       "3            False        False              40                1         0.00   \n",
       "4            False        False              50                2         0.00   \n",
       "\n",
       "   objetividad  \n",
       "0         1.00  \n",
       "1         0.55  \n",
       "2         0.00  \n",
       "3         0.00  \n",
       "4         0.00  \n",
       "\n",
       "[5 rows x 2731 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_limpio = pd.read_csv(\"test_limpio_con_BOW_de_2500_y_Stemming.csv\",encoding = \"ISO-8859-1\")\n",
    "test_limpio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y=train_limpio.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio = train_limpio.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limpio_normalizado = train_limpio.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(train_limpio_normalizado)\n",
    "train_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_limpio_normalizado = test_limpio.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(test_limpio_normalizado)\n",
    "test_limpio_normalizado = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_limpio_normalizado, train_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 76.76056338028168 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "print(f\"Model Score: {f1score * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9288016949428641, 0.9352246030036342, 0.9307978723945535, 0.9317218887646183, 0.9294494209070807]\n",
      "Error de test: [0.7642922911156823, 0.7451959847036329, 0.7239359572326771, 0.7232840880433062, 0.7827675153973228]\n"
     ]
    }
   ],
   "source": [
    "training_error=[]\n",
    "test_error=[]\n",
    "\n",
    "for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "    print('iter')\n",
    "    x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "    y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    #error de entrenamiento:\n",
    "    pred = clf.predict(x_train)\n",
    "    training_error.append(f1_score(y_train.values, pred, average='macro'))\n",
    "    \n",
    "    \n",
    "        \n",
    "    #error de test:\n",
    "    pred = clf.predict(x_test)\n",
    "    test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "    \n",
    "print('Error de entrenamiento:',training_error)\n",
    "print('Error de test:',test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9154378188866442, 0.9271545300375148, 0.9237955311543288, 0.9229971808194587, 0.9206298526868125]\n",
      "Error de test: [0.7379743472928948, 0.7165322433487828, 0.7243931739840448, 0.7010311041350932, 0.7449074570433953]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9622416717364453, 0.9644151144422797, 0.9637843807512156, 0.9636212133326526, 0.9593259409368056]\n",
      "Error de test: [0.6879098360655738, 0.6914848609791513, 0.6821078704219081, 0.6374081617807521, 0.6859677752143004]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9778070583237588, 0.9790539287661881, 0.9815437197474691, 0.9802506525980271, 0.9778723340767541]\n",
      "Error de test: [0.6498467637349024, 0.664296350481683, 0.655225067738834, 0.6492326787263012, 0.6760274385340335]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9804850561673952, 0.9809017049325791, 0.9832408966485824, 0.9827603656113901, 0.9804071441564953]\n",
      "Error de test: [0.6354898848663493, 0.6782830281509369, 0.6572747058949476, 0.6324046393550845, 0.665532277117643]\n"
     ]
    }
   ],
   "source": [
    "c=[1, 10, 100, 1000]\n",
    "\n",
    "for i in c:\n",
    "    training_error=[]\n",
    "    test_error=[]\n",
    "\n",
    "    for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "        print('iter')\n",
    "        x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "        y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "        clf = svm.SVC(C=i,kernel='linear')\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        #error de entrenamiento:\n",
    "        pred = clf.predict(x_train)\n",
    "        training_error.append(f1_score(y_train.values, pred, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "        #error de test:\n",
    "        pred = clf.predict(x_test)\n",
    "        test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "\n",
    "    print('Error de entrenamiento:',training_error)\n",
    "    print('Error de test:',test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.5895916096469676, 0.6237372216929287, 0.5575983129450849, 0.5971716326222111, 0.5401656243045714]\n",
      "Error de test: [0.5832002409735234, 0.5259419279907085, 0.39271438730017794, 0.47352507847030934, 0.43635516007858566]\n",
      "[1, 0.0001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.35800126502213786, 0.36150136296917595, 0.3682572614107884, 0.36126258389261745, 0.36683991683991685]\n",
      "Error de test: [0.383151073309032, 0.36988001654944147, 0.34211663066954645, 0.37081438610996276, 0.3481798715203426]\n",
      "[10, 0.001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.8202795632375794, 0.8268043886328278, 0.819747677221876, 0.8210055210254532, 0.8204181126164811]\n",
      "Error de test: [0.7423605133030371, 0.7288794331154784, 0.6957981259549713, 0.6928563327004291, 0.7635283936833472]\n",
      "[10, 0.0001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.5959586885321828, 0.6280563402385436, 0.5635153701966001, 0.6021612240968435, 0.5488989470184722]\n",
      "Error de test: [0.5858229539786016, 0.5306951185317728, 0.3982759652798563, 0.47643236325400645, 0.4453487943732697]\n",
      "[100, 0.001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.8789371473016292, 0.8892331855400755, 0.8831356938515942, 0.8865478527726429, 0.8823350188433696]\n",
      "Error de test: [0.7641355135774209, 0.7223966431818352, 0.7462678015464737, 0.7217267648552566, 0.7839355682280164]\n",
      "[100, 0.0001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.8202277867950343, 0.8263262622174018, 0.8191075878630791, 0.8217288123643168, 0.8203546647882949]\n",
      "Error de test: [0.7420672142253006, 0.7280180412185043, 0.6952045104791349, 0.6934442400804879, 0.7639339768284061]\n",
      "[1000, 0.001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "Error de entrenamiento: [0.9467458257254109, 0.9510531003390315, 0.9465817543638408, 0.9465960321330945, 0.9454414101887426]\n",
      "Error de test: [0.716574883102429, 0.7041058778717142, 0.7068245562078637, 0.6838516493575091, 0.7215889717942707]\n",
      "[1000, 0.0001]\n",
      "iter\n",
      "iter\n",
      "iter\n",
      "iter\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d1ea874af237>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#error de entrenamiento:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=[[1,0.001],[1,0.0001],[10,0.001],[10,0.0001],[100,0.001],[100,0.0001],[1000,0.001],[1000,0.0001]]\n",
    "\n",
    "for i in x:\n",
    "    training_error=[]\n",
    "    test_error=[]\n",
    "    print(i)\n",
    "    for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "        print('iter')\n",
    "        x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "        y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "        clf = svm.SVC(C=i[0],gamma=i[1])\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        #error de entrenamiento:\n",
    "        pred = clf.predict(x_train)\n",
    "        training_error.append(f1_score(y_train.values, pred, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "        #error de test:\n",
    "        pred = clf.predict(x_test)\n",
    "        test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "\n",
    "    print('Error de entrenamiento:',training_error)\n",
    "    print('Error de test:',test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El maximo fue con: [100, 0.001], veo por sus bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 0.001]\n",
      "Error de entrenamiento: [0.871920203407629, 0.8851840696117804, 0.8777675885406698, 0.8808512203213712, 0.8766290828343981]\n",
      "Error de test: [0.7703612366684872, 0.7278236634378985, 0.744703257237507, 0.7188505557064736, 0.785893105749009]\n",
      "[100, 0.001]\n",
      "Error de entrenamiento: [0.8789371473016292, 0.8892331855400755, 0.8831356938515942, 0.8865478527726429, 0.8823350188433696]\n",
      "Error de test: [0.7641355135774209, 0.7223966431818352, 0.7462678015464737, 0.7217267648552566, 0.7839355682280164]\n",
      "[120, 0.001]\n",
      "Error de entrenamiento: [0.8845416240930273, 0.8959675265418772, 0.8877426018559915, 0.8915148940066642, 0.8878394803704857]\n",
      "Error de test: [0.7618337839227625, 0.7135965416882095, 0.7444051192712682, 0.7248660228170438, 0.7820445915719152]\n"
     ]
    }
   ],
   "source": [
    "x=[[80, 0.001],[100, 0.001], [120, 0.001]]\n",
    "\n",
    "for i in x:\n",
    "    training_error=[]\n",
    "    test_error=[]\n",
    "    print(i)\n",
    "    for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "        x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "        y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "        clf = svm.SVC(C=i[0],gamma=i[1])\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        #error de entrenamiento:\n",
    "        pred = clf.predict(x_train)\n",
    "        training_error.append(f1_score(y_train.values, pred, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "        #error de test:\n",
    "        pred = clf.predict(x_test)\n",
    "        test_error.append(f1_score(y_test.values, pred, average='macro'))\n",
    "\n",
    "    print('Error de entrenamiento:',training_error)\n",
    "    print('Error de test:',test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW de 500:\n",
    "Error de entrenamiento: [0.9036035333541272, 0.9093469488061671, 0.9055951846656467, 0.908319383971707, 0.9056325432275374]\n",
    "Error de test: [0.7523721038267233, 0.7313520975534933, 0.715298389537034, 0.6860331850461006, 0.7619960184657876]\n",
    "    \n",
    "BOW de 1000:\n",
    "Error de entrenamiento: [0.9144565000501346, 0.9202991537002544, 0.9164692765091506, 0.918243887496519, 0.9168028275156694]\n",
    "Error de test: [0.7615579274897103, 0.744663664144243, 0.7271458610317483, 0.7352780944139626, 0.7832437733699391]\n",
    "    \n",
    "BOW de 1500:\n",
    "Error de entrenamiento: [0.9183495169859025, 0.9240663680071464, 0.9222410689086324, 0.9219469596125256, 0.9192158710855989]\n",
    "Error de test: [0.7578230517950811, 0.7448159847015519, 0.7385114704860527, 0.7146224519861784, 0.7792601353429577]\n",
    "    \n",
    "BOW de 2000\n",
    "Error de entrenamiento: [0.9209437005267092, 0.9282109885651806, 0.9250446884068524, 0.9255420048144667, 0.9223689527692223]\n",
    "Error de test: [0.7634241416737515, 0.7429827505329677, 0.7248590220271185, 0.7173043482076129, 0.7790212053446008]\n",
    "    \n",
    "BOw de 2500(el mejor por ahora):\n",
    "Error de entrenamiento: [0.9241660802251935, 0.9297554251416461, 0.9260564112760288, 0.9282990612675541, 0.924205956762895]\n",
    "Error de test: [0.7668899969828157, 0.7487910499559515, 0.7260748150134895, 0.7417172048245112, 0.7812515158429165]\n",
    "    \n",
    "BOW de 5000\n",
    "Error de entrenamiento: [0.9288016949428641, 0.9352246030036342, 0.9307978723945535, 0.9317218887646183, 0.9294494209070807]\n",
    "Error de test: [0.7642922911156823, 0.7451959847036329, 0.7239359572326771, 0.7232840880433062, 0.7827675153973228]\n",
    "    \n",
    "Me quedo con el de 2500, despues lo tunneo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entreno y calculo el feature de prediccion con kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error=[]\n",
    "train_pred = []\n",
    "print('iter')\n",
    "for train_index,test_index in kf.split(train_limpio_normalizado):\n",
    "    x_train,x_test = train_limpio_normalizado.loc[train_index], train_limpio_normalizado.loc[test_index]\n",
    "    y_train,y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    model = svm.SVC(C=80,gamma=0.001)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    #error de test:\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    train_pred.extend(y_pred_binary)\n",
    "    \n",
    "    error = f1_score(y_test.values, y_pred_binary, average='macro')\n",
    "    print(error)\n",
    "    test_error.append(error)\n",
    "    \n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo guardo\n",
    "train = pd.read_csv(\"train.csv\",encoding = \"ISO-8859-1\")\n",
    "train.target = train_pred\n",
    "train[['id','target']].to_csv('pred_train_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizo la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_limpio_normalizado, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_limpio_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediccion_SVM_2500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2192\n",
       "1    1071\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
